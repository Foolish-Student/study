# 第6讲：大型语言模型修练史— 第一阶段: 自我学习，累积实力

## **背景知识与模型训练**  
- 大型语言模型的训练分为三个阶段，第一阶段专注于自我学习和能力积累。  
- 训练数据是模型学习的基础，模型通过训练数据来优化其参数。  
- 训练过程中，机器学习的关键是找到合适的参数，这一过程称为训练或学习。

## **自我学习与文字接龙**  
- 语言模型的核心功能是“文字接龙”，即根据输入生成下一个符号（Token）。  
- 模型通过接收未完成的句子并输出可能的接续Token来进行学习。  
- 学习的有效性依赖于模型对语言和世界知识的理解。

## **训练数据的重要性**  
- 训练数据的多样性和数量直接影响模型的学习效果，缺乏多样性可能导致模型产生偏差。  
- 自我监督学习可以通过网络爬虫自动收集大量数据，从而减少人工干预。  
- 在数据收集过程中，需要对内容进行清洗，以去除无关或低质量的信息。

## **训练过程中的挑战**  
- 训练成功但测试失败的情况（即过拟合）是常见问题，可能导致模型无法泛化到未见数据。  
- 训练过程中的超参数设置对结果有显著影响，通常需要多次调整以优化性能。  
- 找到合理的初始参数也是一个挑战，通常需要随机生成或根据经验进行设置。

## **后天努力与模型表现**  
- 模型的最终表现不仅依赖于其参数数量（即“天资”），也依赖于所用训练数据的质量和数量（即“努力”）。  
- 随着模型规模的扩大，训练数据的丰富性和多样性对于提高准确率至关重要。  
- 尽管GPT-3等大型模型具有强大的参数量，但在某些情况下仍然可能无法提供可靠的答案，反映出对问题理解的局限性。