# 第7讲：大型语言模型修练史— 第二阶段: 名师指点，发挥潜力(兼谈对ChatGPT 做逆向工程与LLaMA 时代的开始)

## **第一阶段与第二阶段的语言模型修炼**

* 第一阶段的语言模型通过自我学习积累知识，但缺乏有效的应用方法。
* 第二阶段则引入人类教师的指导，旨在提升语言模型的潜力。
* 这一阶段的重点在于人类教师准备的教材，包括问题及对应的正确答案，形成可用于训练的资料。

## **训练资料的准备过程**

* 人类教师需预先设计问题，并提供每个问题的正确答案，这些资料可转换为模型的训练格式。
* 训练资料的收集与标注是一个耗时且需要大量人力的过程，被称为资料标注。
* 通过这种方式生成的资料用于监督学习，使模型能够根据指令进行正确的响应。

## **指令微调的关键概念**

* 指令微调（instruction fine-tuning）是将人类教师提供的指令应用于模型训练的过程，增强模型的灵活性和准确性。
* 微调过程中，模型学习如何根据指令生成正确的输出。
* 这一过程通常所需的数据量并不需要非常庞大，数据质量的精准性更为重要。

## **逆向工程与模型的通才化**

* 逆向工程的方法可用于从现有模型（如ChatGPT）中提取有效的训练数据，并进行自己的指令微调。
* 利用ChatGPT的能力生成问题及其答案，能帮助建立一个高效的训练数据集。
* 随着Meta发布LLaMA，更多用户可以利用这些开源模型进行自我微调，打造自己的语言模型。

## **实验成果与未来发展**

* OpenAI 的 InstructGPT 和 Google 的 FLAN 等模型经过指令微调后，表现显著优于未经调整的版本。
* 随着越来越多的模型和技术发展，通才模型的训练与应用将成为未来的主要方向。
* 这些进展标志着大型语言模型的训练不再是少数企业的专利，普通用户也能够参与这一过程。
